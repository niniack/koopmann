{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from IPython.display import clear_output, display\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from analysis.common import load_model\n",
    "from koopmann import aesthetics\n",
    "from koopmann.data import DatasetConfig, get_dataset_class\n",
    "from koopmann.log import logger\n",
    "from koopmann.utils import get_device, set_seed\n",
    "from scripts.train_ae.shape_metrics import build_acts_dict, preprocess_acts\n",
    "\n",
    "set_seed(21)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "model_name = f\"convresnet_{dataset_name}\"\n",
    "file_dir = \"/Users/nsa325/Documents/koopmann_model_saves\"\n",
    "data_root = \"/Users/nsa325/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"lotusroot\":\n",
    "    dim = 20\n",
    "    scale_idx = 1\n",
    "    k_steps = 100\n",
    "    flavor = \"exponential\"\n",
    "elif dataset_name == \"mnist\":\n",
    "    dim = 800\n",
    "    scale_idx = 1\n",
    "    k_steps = 10\n",
    "    flavor = \"exponential\"\n",
    "elif dataset_name == \"cifar10\":\n",
    "    dim = 1_000\n",
    "    scale_idx = 1\n",
    "    k_steps = 100\n",
    "    flavor = \"exponential\"\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "ae_name = f\"dim_{dim}_k_{k_steps}_loc_{scale_idx}_{flavor}_autoencoder_{dataset_name}_model\"\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/nsa325/Documents/koopmann_model_saves/convresnet_cifar10.safetensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, model_metadata = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model.eval().hook_model().to(device)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[33m\"\u001b[39m, model_metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/koopmann/analysis/common.py:42\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(file_dir, model_name)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# model.modules[-3].update_nonlinearity(\"leaky_relu\")\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mresnet\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lower_model_name:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     model, model_metadata = \u001b[43mConvResNet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mres\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lower_model_name:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/koopmann/koopmann/mixins/serializable.py:112\u001b[39m, in \u001b[36mSerializable.load_model\u001b[39m\u001b[34m(cls, file_path, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load model from file.\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Parse metadata\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m metadata = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_safetensors_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Convert metadata values from strings\u001b[39;00m\n\u001b[32m    115\u001b[39m parsed_metadata = \u001b[38;5;28mcls\u001b[39m._parse_metadata(metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/koopmann/koopmann/mixins/serializable.py:40\u001b[39m, in \u001b[36mSerializable.parse_safetensors_metadata\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     38\u001b[39m header_size = \u001b[32m8\u001b[39m\n\u001b[32m     39\u001b[39m meta_data = {}\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m.st_size > header_size:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     42\u001b[39m         b8 = f.read(header_size)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/nsa325/Documents/koopmann_model_saves/convresnet_cifar10.safetensors'"
     ]
    }
   ],
   "source": [
    "model, model_metadata = load_model(file_dir, model_name)\n",
    "model.eval().hook_model().to(device)\n",
    "print(\"Model: \", model_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig(\n",
    "    dataset_name=model_metadata[\"dataset\"],\n",
    "    num_samples=3_000,\n",
    "    split=\"train\",\n",
    "    seed=42,\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=dataset_config.dataset_name)\n",
    "dataset = DatasetClass(config=dataset_config, root=data_root)\n",
    "\n",
    "subset_size = None\n",
    "if subset_size:\n",
    "    subset_indices = list(range(0, subset_size))\n",
    "    subset = Subset(dataset, subset_indices)\n",
    "\n",
    "batch_size = 5_000\n",
    "batch_size = min(subset_size, batch_size) if subset_size else batch_size\n",
    "dataloader = DataLoader(subset if subset_size else dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_act_dict = build_acts_dict(\n",
    "    data_train_loader=dataloader, model=model, only_first_last=False, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_dim = 3\n",
    "whiten_alpha = 0.5\n",
    "processed_act_dict = preprocess_acts(\n",
    "    original_act_dict=original_act_dict,\n",
    "    svd_dim=svd_dim,\n",
    "    whiten_alpha=whiten_alpha,\n",
    "    preprocess_dict={},\n",
    "    device=device,\n",
    "    skip_svd=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(change):\n",
    "    # First clear everything\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Re-display the slider first (so it appears above the plot)\n",
    "    display(layer_slider)\n",
    "\n",
    "    # Get the selected layer index and key\n",
    "    coords = processed_act_dict[layer_keys[layer_slider.value]].cpu()\n",
    "    target_categories = [str(t) for t in dataset.labels[:subset_size]]\n",
    "\n",
    "    # Create and display the new plot\n",
    "    fig = px.scatter_3d(\n",
    "        x=coords[:, 0],\n",
    "        y=coords[:, 1],\n",
    "        z=coords[:, 2],\n",
    "        color=target_categories,\n",
    "        color_discrete_sequence=px.colors.qualitative.T10,\n",
    "    )\n",
    "    fig.update_traces(marker_size=2)\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Get the layer keys and convert to a list for indexing\n",
    "layer_keys = list(processed_act_dict.keys())\n",
    "layer_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(layer_keys) - 1,\n",
    "    step=1,\n",
    "    description=\"Layer:\",\n",
    "    continuous_update=False,  # Only update when slider is released\n",
    ")\n",
    "\n",
    "# Connect slider to update function\n",
    "layer_slider.observe(update_plot, names=\"value\")\n",
    "update_plot(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopmann-hxjVWsls-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
