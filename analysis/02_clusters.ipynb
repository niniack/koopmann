{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from rich import print as rprint\n",
    "from safetensors.torch import load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from koopmann import aesthetics\n",
    "from koopmann.data import (\n",
    "    DatasetConfig,\n",
    "    create_data_loader,\n",
    "    get_dataset_class,\n",
    ")\n",
    "from koopmann.models import (\n",
    "    MLP,\n",
    "    Autoencoder,\n",
    "    ExponentialKoopmanAutencoder,\n",
    "    LowRankKoopmanAutoencoder,\n",
    ")\n",
    "from koopmann.models.utils import (\n",
    "    get_device,\n",
    "    parse_safetensors_metadata,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"mnist\"\n",
    "scale_idx = \"0\"\n",
    "k = \"1\"\n",
    "dim = \"1024\"\n",
    "flavor = \"lowrank_20\"\n",
    "# flavor = \"standard\"\n",
    "user = \"nsa325\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{task}_probed\"\n",
    "ae_name = f\"{task}_model\"\n",
    "\n",
    "# Original model path\n",
    "model_file_path = f\"/scratch/{user}/koopmann_model_saves/{model_name}.safetensors\"\n",
    "\n",
    "# Autoenoder path in work dir\n",
    "ae_file_path = f\"/scratch/{user}/koopmann_model_saves/scaling/dim_{dim}_k_{k}_loc_{scale_idx}_{flavor}_autoencoder_{ae_name}.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = MLP.load_model(model_file_path)\n",
    "model.modules[-2].remove_nonlinearity()\n",
    "# model.modules[-3].update_nonlinearity(\"leakyrelu\")\n",
    "model.modules[-3].remove_nonlinearity()\n",
    "model.eval()\n",
    "model.hook_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = parse_safetensors_metadata(file_path=model_file_path)\n",
    "\n",
    "dataset_config = DatasetConfig(\n",
    "    dataset_name=metadata[\"dataset\"],\n",
    "    num_samples=5_000,\n",
    "    split=\"test\",\n",
    "    seed=21,\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=dataset_config.dataset_name)\n",
    "dataset = DatasetClass(config=dataset_config)\n",
    "dataloader = create_data_loader(dataset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse metadata\n",
    "metadata = parse_safetensors_metadata(file_path=ae_file_path)\n",
    "\n",
    "# Choose model based on flag\n",
    "if \"standard\" in flavor:\n",
    "    AutoencoderClass = Autoencoder\n",
    "elif \"lowrank\" in flavor:\n",
    "    AutoencoderClass = LowRankKoopmanAutoencoder\n",
    "\n",
    "# Instantiate model\n",
    "autoencoder = AutoencoderClass(\n",
    "    input_dimension=literal_eval(metadata[\"input_dimension\"]),\n",
    "    latent_dimension=literal_eval(metadata[\"latent_dimension\"]),\n",
    "    nonlinearity=metadata[\"nonlinearity\"],\n",
    "    k=literal_eval(metadata[\"steps\"]),\n",
    "    batchnorm=literal_eval(metadata[\"batchnorm\"]),\n",
    "    hidden_configuration=literal_eval(metadata[\"hidden_configuration\"]),\n",
    "    rank=literal_eval(metadata[\"rank\"]),\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "load_model(autoencoder, ae_file_path, device=\"cpu\", strict=True)\n",
    "autoencoder.eval()\n",
    "\n",
    "# Remove parameterizations\n",
    "if torch.nn.utils.parametrize.is_parametrized(autoencoder.koopman_matrix.linear_layer):\n",
    "    torch.nn.utils.parametrize.remove_parametrizations(\n",
    "        autoencoder.koopman_matrix.linear_layer, \"weight\"\n",
    "    )\n",
    "\n",
    "K_matrix = autoencoder.koopman_matrix.linear_layer.weight.T.detach()\n",
    "\n",
    "k = literal_eval(metadata[\"num_scaled\"])\n",
    "print(f\"Little K: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def shrink_eigenvalues(matrix, shrink_factor=0.95, indices=None):\n",
    "    # Ensure the matrix is square\n",
    "    assert matrix.shape[0] == matrix.shape[1], \"Input matrix must be square\"\n",
    "\n",
    "    # Compute eigendecomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eig(matrix)\n",
    "    n_eigenvalues = len(eigenvalues)\n",
    "\n",
    "    # Create a copy of eigenvalues to modify\n",
    "    shrunk_eigenvalues = eigenvalues.clone()\n",
    "\n",
    "    if indices is not None:\n",
    "        # Convert list to tensor if needed\n",
    "        if isinstance(indices, list):\n",
    "            indices = torch.tensor(indices)\n",
    "\n",
    "        # Validate indices\n",
    "        assert torch.all(\n",
    "            (indices >= 0) & (indices < n_eigenvalues)\n",
    "        ), f\"All indices must be between 0 and {n_eigenvalues-1}\"\n",
    "\n",
    "        # Find the top eigenvalues by magnitude\n",
    "        eig_magnitudes = torch.abs(eigenvalues)\n",
    "        _, top_magnitude_indices = torch.topk(eig_magnitudes, n_eigenvalues)\n",
    "\n",
    "        # Select the specified indices from the sorted top eigenvalues\n",
    "        selected_indices = top_magnitude_indices[indices]\n",
    "\n",
    "        print(indices)\n",
    "        print(\"real\", selected_indices)\n",
    "        print(eigenvalues[selected_indices])\n",
    "\n",
    "        # Shrink only the selected top eigenvalues\n",
    "        shrunk_eigenvalues[selected_indices] = eigenvalues[selected_indices] * shrink_factor\n",
    "\n",
    "    else:\n",
    "        # Shrink all eigenvalues\n",
    "        shrunk_eigenvalues = eigenvalues * shrink_factor\n",
    "\n",
    "    # Reconstruct the matrix with shrunk eigenvalues\n",
    "    # For a matrix A = PDP^(-1), where D is diagonal matrix of eigenvalues\n",
    "    # and P is matrix of eigenvectors\n",
    "    eigenvectors_inv = torch.linalg.inv(eigenvectors)\n",
    "    diagonal_matrix = torch.diag(shrunk_eigenvalues)\n",
    "    modified_matrix = eigenvectors @ diagonal_matrix @ eigenvectors_inv\n",
    "\n",
    "    # Handle numerical issues - if the output should be real, remove small imaginary parts\n",
    "    if torch.is_complex(matrix):\n",
    "        return modified_matrix\n",
    "    else:\n",
    "        # Check if imaginary parts are negligible\n",
    "        if torch.max(torch.abs(modified_matrix.imag)) < 1e-10:\n",
    "            return modified_matrix.real, (\n",
    "                eigenvalues[selected_indices],\n",
    "                eigenvectors[selected_indices],\n",
    "            )\n",
    "        else:\n",
    "            # If not negligible, there might be an issue\n",
    "            print(\"Warning: Reconstructed matrix has non-negligible imaginary parts\")\n",
    "            return modified_matrix.real, (\n",
    "                eigenvalues[selected_indices],\n",
    "                eigenvectors[selected_indices],\n",
    "            )\n",
    "\n",
    "\n",
    "indices = []\n",
    "if len(indices) == 0:\n",
    "    mod_K_matrix = K_matrix\n",
    "else:\n",
    "    mod_K_matrix, (sel_eigen) = shrink_eigenvalues(K_matrix, shrink_factor=0.5, indices=indices)\n",
    "    sel_eigenvalues, sel_eigenvectors = sel_eigen\n",
    "autoencoder.koopman_matrix.linear_layer.weight = torch.nn.Parameter(mod_K_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unproc_data = (dataset.data.float() / 255)[:500]\n",
    "labels = (dataset.labels)[:500]\n",
    "\n",
    "###############################################################\n",
    "# TODO: This is quick and dirty\n",
    "# Convert [0,1] range to [-1,1]\n",
    "proc_data = 2 * unproc_data - 1\n",
    "###############################################################\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_obs = autoencoder._encode(proc_data)\n",
    "    pred_obs = autoencoder.koopman_matrix(x_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Convert to numpy for sklearn compatibility (if needed)\n",
    "x_obs_np = x_obs.cpu().numpy()\n",
    "pred_obs_np = pred_obs.cpu().numpy()\n",
    "\n",
    "# Use PCA for dimensionality reduction to 3D\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "pred_obs_pca_3d = pca.fit_transform(pred_obs_np)\n",
    "x_obs_pca_3d = pca.transform(x_obs_np)\n",
    "\n",
    "# Check explained variance for 3 components\n",
    "explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"Total explained variance with 3 PCA components: {explained_variance:.3f}\")\n",
    "print(f\"Component 1: {pca.explained_variance_ratio_[0]:.3f}\")\n",
    "print(f\"Component 2: {pca.explained_variance_ratio_[1]:.3f}\")\n",
    "print(f\"Component 3: {pca.explained_variance_ratio_[2]:.3f}\")\n",
    "\n",
    "# Create a DataFrame for Plotly Express\n",
    "unique_labels = np.unique(labels.cpu().numpy())\n",
    "labels_as_str = [f\"Class {label}\" for label in labels.cpu().numpy()]\n",
    "\n",
    "# Prepare data for original and predicted observations\n",
    "df_orig = pd.DataFrame(\n",
    "    {\n",
    "        \"PC1\": x_obs_pca_3d[:, 0],\n",
    "        \"PC2\": x_obs_pca_3d[:, 1],\n",
    "        \"PC3\": x_obs_pca_3d[:, 2],\n",
    "        \"Class\": labels_as_str,\n",
    "        \"Type\": \"Original\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pred = pd.DataFrame(\n",
    "    {\n",
    "        \"PC1\": pred_obs_pca_3d[:, 0],\n",
    "        \"PC2\": pred_obs_pca_3d[:, 1],\n",
    "        \"PC3\": pred_obs_pca_3d[:, 2],\n",
    "        \"Class\": labels_as_str,\n",
    "        \"Type\": \"Predicted\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Combine the DataFrames\n",
    "df = pd.concat([df_orig, df_pred])\n",
    "\n",
    "# Define a discrete color mapping dictionary\n",
    "colors = px.colors.qualitative.Bold\n",
    "color_discrete_map = {}\n",
    "\n",
    "# Create mapping from class names to colors\n",
    "for i, label in enumerate(unique_labels):\n",
    "    color_idx = i % len(colors)\n",
    "    class_name = f\"Class {label}\"\n",
    "    color_discrete_map[class_name] = colors[color_idx]\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=\"Class\",\n",
    "    symbol=\"Type\",\n",
    "    color_discrete_map=color_discrete_map,\n",
    "    opacity=0.7,\n",
    "    labels={\n",
    "        \"PC1\": f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} var)\",\n",
    "        \"PC2\": f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} var)\",\n",
    "        \"PC3\": f\"PC3 ({pca.explained_variance_ratio_[2]:.1%} var)\",\n",
    "    },\n",
    "    title=\"3D Movement in PCA-Reduced Latent Space\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "# Add lines connecting original and predicted points\n",
    "sample_rate = max(1, len(x_obs_np) // 300)\n",
    "\n",
    "for i in range(0, len(x_obs_pca_3d), sample_rate):\n",
    "    class_label = labels.cpu().numpy()[i]\n",
    "    class_name = f\"Class {class_label}\"\n",
    "    color = color_discrete_map[class_name]\n",
    "\n",
    "    # Add connecting line with transparency but without the problematic opacity parameter\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[x_obs_pca_3d[i, 0], pred_obs_pca_3d[i, 0]],\n",
    "            y=[x_obs_pca_3d[i, 1], pred_obs_pca_3d[i, 1]],\n",
    "            z=[x_obs_pca_3d[i, 2], pred_obs_pca_3d[i, 2]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(\n",
    "                color=color.replace(\"rgb\", \"rgba\").replace(\n",
    "                    \")\", \", 0.3)\"\n",
    "                ),  # Add transparency to color directly\n",
    "                width=1,\n",
    "            ),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update the layout for better viewing\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"Class Labels\",\n",
    "    scene=dict(\n",
    "        xaxis_title=f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} var)\",\n",
    "        yaxis_title=f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} var)\",\n",
    "        zaxis_title=f\"PC3 ({pca.explained_variance_ratio_[2]:.1%} var)\",\n",
    "    ),\n",
    "    scene_camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n",
    "\n",
    "print(\"Tip: You can rotate, zoom, and pan the plot using your mouse!\")\n",
    "print(\n",
    "    \"Tip: Double-click on a class in the legend to isolate it, or single-click to toggle visibility.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
