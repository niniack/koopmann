{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from safetensors import safe_open\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "from analysis.utils import load_autoencoder, load_model\n",
    "from koopmann import aesthetics\n",
    "from koopmann.data import DatasetConfig, get_dataset_class\n",
    "from koopmann.models import ConvResNet\n",
    "from koopmann.shape_metrics import prepare_acts, undo_preprocessing_acts\n",
    "from koopmann.utils import set_seed\n",
    "\n",
    "set_seed(36)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_file_dir = \"/scratch/nsa325/koopmann_model_saves\"\n",
    "data_root = \"/scratch/nsa325/datasets/\"\n",
    "\n",
    "# dataset_name = \"mnist\"\n",
    "# model_name = f\"resmlp_{dataset_name}\"\n",
    "\n",
    "dataset_name = \"mnist\"\n",
    "model_name = f\"resmlp_{dataset_name}\"\n",
    "\n",
    "ae_file_dir = f\"/scratch/nsa325/koopmann_model_saves/{dataset_name}\"\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MLP Metadata: \n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'batchnorm'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bias'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-04-09T02:41:58.432513'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'MNISTDataset'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_config'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'in_features'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_class'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ResMLP'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'nonlinearity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'relu'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'out_features'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'stochastic_depth_mode'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'batch'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'stochastic_depth_prob'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MLP Metadata: \n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'batchnorm'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'bias'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-04-09T02:41:58.432513'\u001b[0m,\n",
       "    \u001b[32m'dataset'\u001b[0m: \u001b[32m'MNISTDataset'\u001b[0m,\n",
       "    \u001b[32m'hidden_config'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m784\u001b[0m, \u001b[1;36m784\u001b[0m, \u001b[1;36m784\u001b[0m, \u001b[1;36m784\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'in_features'\u001b[0m: \u001b[1;36m784\u001b[0m,\n",
       "    \u001b[32m'model_class'\u001b[0m: \u001b[32m'ResMLP'\u001b[0m,\n",
       "    \u001b[32m'nonlinearity'\u001b[0m: \u001b[32m'relu'\u001b[0m,\n",
       "    \u001b[32m'out_features'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
       "    \u001b[32m'stochastic_depth_mode'\u001b[0m: \u001b[32m'batch'\u001b[0m,\n",
       "    \u001b[32m'stochastic_depth_prob'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, model_metadata = load_model(mlp_file_dir, model_name)\n",
    "model.hook_model().eval().to(device)\n",
    "rprint(\"MLP Metadata: \", model_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "test_dataset_config = DatasetConfig(\n",
    "    dataset_name=model_metadata[\"dataset\"], num_samples=5_000, split=\"test\", seed=42\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=test_dataset_config.dataset_name)\n",
    "test_dataset = DatasetClass(config=test_dataset_config, root=data_root)\n",
    "test_labels = test_dataset.labels.squeeze()\n",
    "\n",
    "# Make dataloader\n",
    "batch_size = 5_000\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_files = sorted(os.listdir(ae_file_dir))\n",
    "ae_files = [\n",
    "    Path(file) for file in ae_files if (\"autoencoder\" in file and \"preprocessing\" not in file)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def koopman_intermediates(\n",
    "    init_idx,\n",
    "    final_idx,\n",
    "    orig_act_dict,\n",
    "    proc_act_dict,\n",
    "    device,\n",
    "    preproc_dict,\n",
    "    autoencoder,\n",
    "    model,\n",
    "    preprocess,\n",
    "    k_steps,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        # x = orig_act_dict[init_idx]\n",
    "        # y = orig_act_dict[final_idx]\n",
    "\n",
    "        x_proj = proc_act_dict[init_idx]\n",
    "        y_proj = proc_act_dict[final_idx]\n",
    "\n",
    "        # if preprocess:\n",
    "        #     x_unproj = undo_preprocessing_acts(x_proj, preproc_dict, init_idx, device)\n",
    "        #     y_unproj = undo_preprocessing_acts(y_proj, preproc_dict, final_idx, device)\n",
    "        # else:\n",
    "        #     x_unproj = x_proj\n",
    "        #     y_unproj = y_proj\n",
    "\n",
    "        # Reconstruct first act\n",
    "        x_proj_obs = autoencoder.encode(x_proj)\n",
    "        x_proj_recon = autoencoder.decode(x_proj_obs)\n",
    "\n",
    "        # Reconstruct final act\n",
    "        y_proj_obs = autoencoder.encode(y_proj)\n",
    "        y_proj_recon = autoencoder.decode(y_proj_obs)\n",
    "\n",
    "        pred_proj_obs = autoencoder.koopman_forward(x_proj_obs, k_steps)\n",
    "        pred_proj = autoencoder.decode(pred_proj_obs)\n",
    "\n",
    "        if preprocess:\n",
    "            pred = undo_preprocessing_acts(pred_proj, preproc_dict, final_idx, device)\n",
    "            y_recon = undo_preprocessing_acts(y_proj_recon, preproc_dict, final_idx, device)\n",
    "        else:\n",
    "            pred = pred_proj\n",
    "            y_recon = y_proj_recon\n",
    "\n",
    "        pred = model.components[-1:](pred)\n",
    "\n",
    "        # Return all requested variables in a dictionary\n",
    "        results = {\n",
    "            \"x_proj\": x_proj,\n",
    "            \"y_proj\": y_proj,\n",
    "            \"x_proj_obs\": x_proj_obs,\n",
    "            \"y_proj_obs\": y_proj_obs,\n",
    "            \"pred_proj_obs\": pred_proj_obs,\n",
    "            \"x_proj_recon\": x_proj_recon,\n",
    "            \"y_proj_recon\": y_proj_recon,\n",
    "            \"y_recon\": y_recon,\n",
    "            \"pred_proj\": pred_proj,\n",
    "            \"pred\": pred,\n",
    "        }\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_per_class_metric = MulticlassAccuracy(num_classes=test_dataset.out_features, average=None)\n",
    "for inputs, labels in test_dataloader:\n",
    "    mlp_pred = model(inputs)\n",
    "    mlp_per_class_metric.update(mlp_pred, labels.squeeze().long())\n",
    "mlp_acc = mlp_per_class_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activations: 100%|██████████| 2/2 [00:00<00:00, 19.60it/s]\n",
      "Processing activations: 100%|██████████| 2/2 [00:00<00:00, 19.08it/s]\n",
      "Processing activations: 100%|██████████| 2/2 [00:00<00:00, 12.15it/s]\n",
      "Processing activations: 100%|██████████| 2/2 [00:00<00:00, 14.83it/s]\n",
      "Processing activations: 100%|██████████| 2/2 [00:00<00:00, 13.12it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "\n",
    "for ae_file in ae_files:\n",
    "    # Load preprocessing dict and autoencoder\n",
    "    preproc_dict = {}\n",
    "    with safe_open(\n",
    "        f\"{ae_file_dir}/{ae_file.stem}_preprocessing.safetensors\", framework=\"pt\", device=device\n",
    "    ) as f:\n",
    "        for k in f.keys():\n",
    "            preproc_dict[k] = f.get_tensor(k)\n",
    "    autoencoder, ae_metadata = load_autoencoder(ae_file_dir, ae_file.stem)\n",
    "    seed_loc_in_str = ae_file.stem.find(\"seed_\") + 5\n",
    "    seed = int(ae_file.stem[seed_loc_in_str:])\n",
    "\n",
    "    # Prepared activations\n",
    "    orig_act_dict, processed_act_dict, _ = prepare_acts(\n",
    "        data_train_loader=test_dataloader,\n",
    "        model=model,\n",
    "        device=device,\n",
    "        svd_dim=ae_metadata[\"in_features\"],\n",
    "        whiten_alpha=preproc_dict[\"wh_alpha_0\"],\n",
    "        preprocess=True,\n",
    "        preprocess_dict=preproc_dict,\n",
    "        only_first_last=True,\n",
    "    )\n",
    "    init_idx = list(orig_act_dict.keys())[0]\n",
    "    final_idx = list(orig_act_dict.keys())[-1]\n",
    "\n",
    "    # Koopman intermediates\n",
    "    test_intermediates = koopman_intermediates(\n",
    "        init_idx=init_idx,\n",
    "        final_idx=final_idx,\n",
    "        orig_act_dict=orig_act_dict,\n",
    "        proc_act_dict=processed_act_dict,\n",
    "        device=device,\n",
    "        preproc_dict=preproc_dict,\n",
    "        autoencoder=autoencoder,\n",
    "        model=model,\n",
    "        preprocess=True,\n",
    "        k_steps=ae_metadata[\"k_steps\"],\n",
    "    )\n",
    "    pred = test_intermediates[\"pred\"]\n",
    "    x_proj_obs = test_intermediates[\"x_proj_obs\"]\n",
    "\n",
    "    # Per-class accuracy\n",
    "    per_class_metric = MulticlassAccuracy(num_classes=test_dataset.out_features, average=None)\n",
    "    per_class_metric.update(pred, test_labels.to(torch.long))\n",
    "    # print(\"Koopman accuracy per class (original):\", per_class_metric.compute())\n",
    "    accuracies[seed] = per_class_metric.compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                               mnist Accuracies                                               </span>\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Seed </span>┃<span style=\"font-weight: bold\"> Per-Class Accuracy                                                               </span>┃<span style=\"font-weight: bold\"> Overall Accuracy </span>┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ 21   │ [99.39%, 99.30%, 98.84%, 98.61%, 98.37%, 98.88%, 98.43%, 97.96%, 98.67%, 97.62%] │ 98.61%           │\n",
       "│ 365  │ [99.39%, 99.21%, 98.64%, 98.32%, 98.27%, 98.99%, 98.64%, 98.05%, 98.15%, 97.42%] │ 98.51%           │\n",
       "│ 53   │ [99.39%, 99.21%, 98.84%, 98.42%, 98.27%, 98.32%, 98.54%, 98.35%, 98.46%, 97.52%] │ 98.53%           │\n",
       "│ 74   │ [99.39%, 99.21%, 99.03%, 98.32%, 98.17%, 98.32%, 98.43%, 97.86%, 98.36%, 97.72%] │ 98.48%           │\n",
       "│ 99   │ [99.39%, 99.21%, 98.93%, 98.22%, 98.37%, 98.43%, 98.85%, 97.86%, 98.36%, 97.82%] │ 98.54%           │\n",
       "├──────┼──────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│<span style=\"font-weight: bold\"> Mean </span>│<span style=\"font-weight: bold\"> [99.39%, 99.22%, 98.86%, 98.38%, 98.29%, 98.59%, 98.58%, 98.02%, 98.40%, 97.62%] </span>│<span style=\"font-weight: bold\"> 98.53%           </span>│\n",
       "│<span style=\"font-weight: bold\"> Std  </span>│<span style=\"font-weight: bold\"> [0.00%, 0.04%, 0.13%, 0.13%, 0.08%, 0.29%, 0.16%, 0.18%, 0.17%, 0.14%]           </span>│<span style=\"font-weight: bold\"> 0.04%            </span>│\n",
       "├──────┼──────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│<span style=\"font-weight: bold\"> MLP  </span>│<span style=\"font-weight: bold\"> [99.59%, 99.82%, 99.22%, 98.61%, 98.57%, 98.77%, 99.06%, 99.03%, 98.97%, 98.61%] </span>│<span style=\"font-weight: bold\"> 99.03%           </span>│\n",
       "└──────┴──────────────────────────────────────────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                               mnist Accuracies                                               \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSeed\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPer-Class Accuracy                                                              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOverall Accuracy\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ 21   │ [99.39%, 99.30%, 98.84%, 98.61%, 98.37%, 98.88%, 98.43%, 97.96%, 98.67%, 97.62%] │ 98.61%           │\n",
       "│ 365  │ [99.39%, 99.21%, 98.64%, 98.32%, 98.27%, 98.99%, 98.64%, 98.05%, 98.15%, 97.42%] │ 98.51%           │\n",
       "│ 53   │ [99.39%, 99.21%, 98.84%, 98.42%, 98.27%, 98.32%, 98.54%, 98.35%, 98.46%, 97.52%] │ 98.53%           │\n",
       "│ 74   │ [99.39%, 99.21%, 99.03%, 98.32%, 98.17%, 98.32%, 98.43%, 97.86%, 98.36%, 97.72%] │ 98.48%           │\n",
       "│ 99   │ [99.39%, 99.21%, 98.93%, 98.22%, 98.37%, 98.43%, 98.85%, 97.86%, 98.36%, 97.82%] │ 98.54%           │\n",
       "├──────┼──────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1mMean\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m[99.39%, 99.22%, 98.86%, 98.38%, 98.29%, 98.59%, 98.58%, 98.02%, 98.40%, 97.62%]\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m98.53%          \u001b[0m\u001b[1m \u001b[0m│\n",
       "│\u001b[1m \u001b[0m\u001b[1mStd \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m[0.00%, 0.04%, 0.13%, 0.13%, 0.08%, 0.29%, 0.16%, 0.18%, 0.17%, 0.14%]          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m0.04%           \u001b[0m\u001b[1m \u001b[0m│\n",
       "├──────┼──────────────────────────────────────────────────────────────────────────────────┼──────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1mMLP \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m[99.59%, 99.82%, 99.22%, 98.61%, 98.57%, 98.77%, 99.06%, 99.03%, 98.97%, 98.61%]\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m99.03%          \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴──────────────────────────────────────────────────────────────────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_array(arr, multiplier=100, precision=2):\n",
    "    \"\"\"Format array values as percentages with specified precision\"\"\"\n",
    "    values = [f\"{x*multiplier:.{precision}f}%\" for x in arr]\n",
    "    return \"[\" + \", \".join(values) + \"]\"\n",
    "\n",
    "\n",
    "table = Table(title=f\"{dataset_name} Accuracies\")\n",
    "table.add_column(\"Seed\")\n",
    "table.add_column(\"Per-Class Accuracy\")\n",
    "table.add_column(\"Overall Accuracy\")\n",
    "\n",
    "# Convert dict to numpy arrays for vectorized operations\n",
    "seeds = list(accuracies.keys())\n",
    "values = np.array([v.numpy() for v in accuracies.values()])\n",
    "overall = np.array([v.mean().item() for v in accuracies.values()])\n",
    "\n",
    "# Add individual rows\n",
    "for i, seed in enumerate(seeds):\n",
    "    # Add end_section=True to the last seed row to create a separator line\n",
    "    if i == len(seeds) - 1:\n",
    "        table.add_row(\n",
    "            str(seed), format_array(values[i]), f\"{overall[i]*100:.2f}%\", end_section=True\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(str(seed), format_array(values[i]), f\"{overall[i]*100:.2f}%\")\n",
    "\n",
    "# Add statistics rows\n",
    "table.add_row(\"Mean\", format_array(values.mean(axis=0)), f\"{overall.mean()*100:.2f}%\", style=\"bold\")\n",
    "table.add_row(\n",
    "    \"Std\",\n",
    "    format_array(values.std(axis=0)),\n",
    "    f\"{overall.std()*100:.2f}%\",\n",
    "    style=\"bold\",\n",
    "    end_section=True,\n",
    ")\n",
    "table.add_row(\n",
    "    \"MLP\",\n",
    "    format_array(mlp_per_class_metric.compute()),\n",
    "    f\"{mlp_per_class_metric.compute().mean()*100:.2f}%\",\n",
    "    style=\"bold\",\n",
    ")\n",
    "\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopmann-hxjVWsls-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
