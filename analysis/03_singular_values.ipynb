{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "import torchvision.transforms.functional as TVF\n",
    "from matrepr import mdisplay\n",
    "from plotly.subplots import make_subplots\n",
    "from rich import print as rprint\n",
    "from torch import linalg\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from koopmann import aesthetics\n",
    "from koopmann.data import (\n",
    "    DatasetConfig,\n",
    "    create_data_loader,\n",
    "    get_dataset_class,\n",
    ")\n",
    "from koopmann.models import (\n",
    "    MLP,\n",
    "    Autoencoder,\n",
    "    ExponentialKoopmanAutencoder,\n",
    "    LowRankKoopmanAutoencoder,\n",
    "    ResMLP,\n",
    ")\n",
    "from koopmann.models.utils import get_device\n",
    "from koopmann.visualization import plot_eigenvalues\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.common import (\n",
    "    compare_model_autoencoder_acc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"mnist\"\n",
    "scale_idx = \"0\"\n",
    "k = \"1\"\n",
    "dim = \"1024\"\n",
    "\n",
    "# flavor = \"exponential\"\n",
    "# flavor = \"standard\"\n",
    "flavor = \"lowrank_20\"\n",
    "\n",
    "user = \"nsa325\"\n",
    "\n",
    "model_name = f\"{task}_probed\"\n",
    "ae_name = f\"{task}_model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model path\n",
    "model_file_path = f\"/scratch/{user}/koopmann_model_saves/{model_name}.safetensors\"\n",
    "\n",
    "if \"probed\" in model_name:\n",
    "    model, model_metadata = MLP.load_model(file_path=model_file_path)\n",
    "    model.modules[-2].remove_nonlinearity()\n",
    "    model.modules[-3].remove_nonlinearity()\n",
    "    # model.modules[-3].update_nonlinearity(\"leakyrelu\")\n",
    "    is_probed = True\n",
    "else:\n",
    "    if \"residual\" in model_name:\n",
    "        model, model_metadata = ResMLP.load_model(file_path=model_file_path)\n",
    "    else:\n",
    "        model, model_metadata = MLP.load_model(file_path=model_file_path)\n",
    "    is_probed = False\n",
    "\n",
    "model.eval().hook_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig(\n",
    "    dataset_name=model_metadata[\"dataset\"], num_samples=5_000, split=\"test\", seed=21\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=dataset_config.dataset_name)\n",
    "dataset = DatasetClass(config=dataset_config)\n",
    "\n",
    "# Raw images and labels\n",
    "raw_images, labels = dataset.data, dataset.labels\n",
    "\n",
    "# Processed for MLP\n",
    "mlp_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Lambda(lambda x: x / 255),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "mlp_inputs = mlp_transform(raw_images)\n",
    "\n",
    "# Processed for AE\n",
    "ae_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Lambda(lambda x: x / 255),\n",
    "        transforms.Lambda(lambda x: x * 2 - 1),\n",
    "    ]\n",
    ")\n",
    "ae_inputs = ae_transform(raw_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoenoder path in work dir\n",
    "ae_file_path = f\"/scratch/{user}/koopmann_model_saves/scaling/dim_{dim}_k_{k}_loc_{scale_idx}_{flavor}_autoencoder_{ae_name}.safetensors\"\n",
    "\n",
    "# Choose model based on flag\n",
    "if \"standard\" in flavor:\n",
    "    AutoencoderClass = Autoencoder\n",
    "elif \"lowrank\" in flavor:\n",
    "    AutoencoderClass = LowRankKoopmanAutoencoder\n",
    "elif \"exponential\" in flavor:\n",
    "    AutoencoderClass = ExponentialKoopmanAutencoder\n",
    "\n",
    "autoencoder, ae_metadata = AutoencoderClass.load_model(\n",
    "    ae_file_path,\n",
    "    strict=True,\n",
    "    remove_param=True,\n",
    ")\n",
    "_ = autoencoder.eval()\n",
    "\n",
    "K_matrix = autoencoder.koopman_matrix.linear_layer.weight.T.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_mlp, acc_koopman = compare_model_autoencoder_acc(\n",
    "#     model, autoencoder, int(k), len(dataset.classes), mlp_inputs, ae_inputs, labels\n",
    "# )\n",
    "# mdisplay(acc_mlp, title=\"Original Model Testing Accuracy\")\n",
    "# mdisplay(acc_koopman, title=\"Autoencoder Prediction Testing Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get class-specific inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which indices contain the target class\n",
    "target_label = 0\n",
    "target_idx = torch.where(labels == target_label)\n",
    "\n",
    "# Grab the inputs\n",
    "target_mlp_inputs = mlp_inputs[target_idx]\n",
    "target_ae_inputs = ae_inputs[target_idx]\n",
    "\n",
    "# Compute mlp predictions\n",
    "mlp_output = model(target_mlp_inputs)\n",
    "mlp_predictions = torch.argmax(mlp_output, dim=1)\n",
    "\n",
    "# Koopman outputs\n",
    "koopman_output = autoencoder(target_ae_inputs, k=int(k)).predictions.squeeze(0)\n",
    "koopman_predictions = torch.argmax(model.modules[-2:](koopman_output), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the correct and incorrect indices\n",
    "correct_idx = torch.where(koopman_predictions == target_label)[0]\n",
    "misclassified_idx = torch.where(koopman_predictions != target_label)[0]\n",
    "\n",
    "# Correct MLP inputs\n",
    "correct_mlp_inputs = target_mlp_inputs[correct_idx]\n",
    "correct_ae_inputs = target_ae_inputs[correct_idx]\n",
    "correct_labels = koopman_predictions[correct_idx]\n",
    "\n",
    "# Misclassified by MLP inputs\n",
    "misclassifed_mlp_inputs = target_mlp_inputs[misclassified_idx]\n",
    "misclassified_ae_inputs = target_ae_inputs[misclassified_idx]\n",
    "incorrect_labels = koopman_predictions[misclassified_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "# Compute SVD of Koopman matrix\n",
    "U, S, Vh = torch.linalg.svd(K_matrix)\n",
    "\n",
    "# Identify significant singular values/vectors\n",
    "significant_threshold = 1e-5\n",
    "significant_modes = torch.where(S > significant_threshold)[0]\n",
    "n_significant = len(significant_modes)\n",
    "print(f\"Number of significant modes: {n_significant} out of {len(S)}\")\n",
    "\n",
    "# Encode all samples\n",
    "with torch.no_grad():\n",
    "    # Encode samples\n",
    "    correct_encodings = autoencoder._encode(correct_ae_inputs)\n",
    "    misclass_encodings = autoencoder._encode(misclassified_ae_inputs)\n",
    "\n",
    "    # Project onto significant left singular vectors\n",
    "    sig_U = U[:, significant_modes]\n",
    "    correct_projections = torch.matmul(correct_encodings, sig_U)\n",
    "    misclass_projections = torch.matmul(misclass_encodings, sig_U)\n",
    "\n",
    "    # Convert to numpy for plotting\n",
    "    correct_proj_np = correct_projections.cpu().numpy()\n",
    "    misclass_proj_np = misclass_projections.cpu().numpy()\n",
    "    significant_S = S[significant_modes].cpu().numpy()\n",
    "    significant_modes_np = significant_modes.cpu().numpy()\n",
    "\n",
    "# Create interactive widgets\n",
    "n_correct = len(correct_proj_np)\n",
    "n_misclass = len(misclass_proj_np)\n",
    "\n",
    "\n",
    "@interact(\n",
    "    sample_type=widgets.RadioButtons(\n",
    "        options=[(\"Correctly Classified\", \"correct\"), (\"Misclassified\", \"misclassified\")],\n",
    "        description=\"Sample Type:\",\n",
    "        disabled=False,\n",
    "    ),\n",
    "    sample_idx=widgets.IntSlider(\n",
    "        min=0, max=max(n_correct, n_misclass) - 1, step=1, value=0, description=\"Sample Index:\"\n",
    "    ),\n",
    "    n_modes=widgets.IntSlider(\n",
    "        min=5, max=min(20, n_significant), step=1, value=10, description=\"# of Modes:\"\n",
    "    ),\n",
    "    normalization=widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"Raw Projections\", \"raw\"),\n",
    "            (\"Normalized by Singular Values\", \"normalized\"),\n",
    "            (\"Output Contribution\", \"contribution\"),\n",
    "        ],\n",
    "        value=\"raw\",\n",
    "        description=\"View:\",\n",
    "    ),\n",
    ")\n",
    "def update_plot(sample_type, sample_idx, n_modes, normalization):\n",
    "    # Ensure sample index is valid\n",
    "    if sample_type == \"correct\":\n",
    "        max_idx = n_correct - 1\n",
    "    else:\n",
    "        max_idx = n_misclass - 1\n",
    "\n",
    "    if sample_idx > max_idx:\n",
    "        sample_idx = max_idx\n",
    "\n",
    "    # Get sample data\n",
    "    if sample_type == \"correct\":\n",
    "        sample_input = correct_ae_inputs[sample_idx]\n",
    "        sample_proj = correct_proj_np[sample_idx]\n",
    "        sample_class = target_label\n",
    "        title_color = \"blue\"\n",
    "    else:\n",
    "        sample_input = misclassified_ae_inputs[sample_idx]\n",
    "        sample_proj = misclass_proj_np[sample_idx]\n",
    "        sample_class = incorrect_labels[sample_idx].item()\n",
    "        title_color = \"red\"\n",
    "\n",
    "    # Ensure we don't exceed available modes\n",
    "    n_modes = min(n_modes, n_significant)\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig = sp.make_subplots(\n",
    "        rows=1, cols=2, column_widths=[0.3, 0.7], specs=[[{\"type\": \"image\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "\n",
    "    # Add the input image on the left\n",
    "    img = sample_input.reshape(28, 28).cpu().numpy()\n",
    "    fig.add_trace(go.Heatmap(z=img, colorscale=\"Greys\", showscale=False), row=1, col=1)\n",
    "\n",
    "    # Get modes and projections\n",
    "    mode_indices = significant_modes_np[:n_modes]\n",
    "    raw_values = sample_proj[:n_modes]\n",
    "    singular_values = significant_S[:n_modes]\n",
    "\n",
    "    # Apply requested normalization\n",
    "    if normalization == \"raw\":\n",
    "        proj_values = raw_values\n",
    "        y_label = \"Raw Projection\"\n",
    "    elif normalization == \"normalized\":\n",
    "        proj_values = raw_values / singular_values\n",
    "        y_label = \"Normalized Projection (p/σ)\"\n",
    "    else:  # contribution\n",
    "        proj_values = raw_values * singular_values\n",
    "        y_label = \"Output Contribution (p·σ)\"\n",
    "\n",
    "    # Create a colored bar chart based on projection values\n",
    "    colors = [\"red\" if val < 0 else \"blue\" for val in proj_values]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=mode_indices,\n",
    "            y=proj_values,\n",
    "            marker_color=colors,\n",
    "            text=[f\"σ={sv:.4f}\" for sv in singular_values],\n",
    "            hovertemplate=\"Mode %{x}<br>Value: %{y:.4f}<br>%{text}<extra></extra>\",\n",
    "            name=\"Projections\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    # Customize layout\n",
    "    n_samples = n_correct if sample_type == \"correct\" else n_misclass\n",
    "    sample_status = (\n",
    "        \"Correctly Classified\" if sample_type == \"correct\" else f\"Misclassified as {sample_class}\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"Sample {sample_idx+1}/{n_samples} ({sample_status}, True Class: {target_label})\",\n",
    "        title_font=dict(color=title_color),\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Mode Index\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=y_label, row=1, col=2)\n",
    "\n",
    "    # Add a horizontal line at y=0 for reference\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        line=dict(dash=\"dash\", color=\"black\"),\n",
    "        x0=min(mode_indices) - 0.5,\n",
    "        y0=0,\n",
    "        x1=max(mode_indices) + 0.5,\n",
    "        y1=0,\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "\n",
    "# Define overlap calculation function first\n",
    "def compute_distribution_overlap(dist1, dist2, bins=50):\n",
    "    \"\"\"Compute approximate percentage overlap between two distributions\"\"\"\n",
    "    min_val = min(np.min(dist1), np.min(dist2))\n",
    "    max_val = max(np.max(dist1), np.max(dist2))\n",
    "\n",
    "    # Compute histograms with same bins\n",
    "    hist1, bin_edges = np.histogram(dist1, bins=bins, range=(min_val, max_val), density=True)\n",
    "    hist2, _ = np.histogram(dist2, bins=bins, range=(min_val, max_val), density=True)\n",
    "\n",
    "    # Compute bin width for integration\n",
    "    bin_width = (max_val - min_val) / bins\n",
    "\n",
    "    # Compute overlap\n",
    "    overlap = np.sum(np.minimum(hist1, hist2)) * bin_width * 100\n",
    "\n",
    "    return overlap\n",
    "\n",
    "\n",
    "# Create histogram visualization\n",
    "@interact(\n",
    "    mode_idx=widgets.IntSlider(\n",
    "        min=0, max=min(19, n_significant - 1), step=1, value=0, description=\"Mode:\"\n",
    "    ),\n",
    "    normalization=widgets.Dropdown(\n",
    "        options=[\n",
    "            (\"Raw Projections\", \"raw\"),\n",
    "            (\"Normalized by Singular Values\", \"normalized\"),\n",
    "            (\"Output Contribution\", \"contribution\"),\n",
    "        ],\n",
    "        value=\"raw\",\n",
    "        description=\"View:\",\n",
    "    ),\n",
    ")\n",
    "def plot_projection_histogram(mode_idx, normalization):\n",
    "    # Get the actual mode number and its singular value\n",
    "    mode = significant_modes_np[mode_idx]\n",
    "    sigma = significant_S[mode_idx]\n",
    "\n",
    "    # Get projections for this mode\n",
    "    correct_proj = correct_proj_np[:, mode_idx]\n",
    "    misclass_proj = misclass_proj_np[:, mode_idx]\n",
    "\n",
    "    # Apply normalization\n",
    "    if normalization == \"raw\":\n",
    "        y_label = \"Raw Projection\"\n",
    "    elif normalization == \"normalized\":\n",
    "        correct_proj = correct_proj / sigma\n",
    "        misclass_proj = misclass_proj / sigma\n",
    "        y_label = \"Normalized Projection (p/σ)\"\n",
    "    else:  # contribution\n",
    "        correct_proj = correct_proj * sigma\n",
    "        misclass_proj = misclass_proj * sigma\n",
    "        y_label = \"Output Contribution (p·σ)\"\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add histograms\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=correct_proj, name=\"Correctly Classified\", opacity=0.7, marker_color=\"blue\", nbinsx=30\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=misclass_proj, name=\"Misclassified\", opacity=0.7, marker_color=\"red\", nbinsx=30\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add vertical lines for means\n",
    "    fig.add_vline(\n",
    "        x=np.mean(correct_proj),\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"blue\",\n",
    "        annotation_text=\"Correct Mean\",\n",
    "        annotation_position=\"top right\",\n",
    "    )\n",
    "    fig.add_vline(\n",
    "        x=np.mean(misclass_proj),\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=\"Misclass Mean\",\n",
    "        annotation_position=\"top left\",\n",
    "    )\n",
    "\n",
    "    # Compute effect size\n",
    "    pooled_std = np.sqrt(\n",
    "        (\n",
    "            (len(correct_proj) - 1) * np.var(correct_proj)\n",
    "            + (len(misclass_proj) - 1) * np.var(misclass_proj)\n",
    "        )\n",
    "        / (len(correct_proj) + len(misclass_proj) - 2)\n",
    "    )\n",
    "    effect_size = (np.mean(misclass_proj) - np.mean(correct_proj)) / pooled_std\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Mode {mode} (σ={sigma:.4f}) Projection Distribution - Effect Size: {effect_size:.2f}\",\n",
    "        xaxis_title=y_label,\n",
    "        yaxis_title=\"Count\",\n",
    "        barmode=\"overlay\",\n",
    "        height=500,\n",
    "        width=900,\n",
    "    )\n",
    "\n",
    "    # Add hover data\n",
    "    fig.update_traces(hovertemplate=\"Value: %{x:.4f}<br>Count: %{y}<extra></extra>\")\n",
    "\n",
    "    # Compute separation statistics\n",
    "    overlap = compute_distribution_overlap(correct_proj, misclass_proj)\n",
    "    fig.add_annotation(\n",
    "        x=0.5,\n",
    "        y=1.05,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=f\"Distribution Overlap: {overlap:.1f}%\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=14),\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute SVD of Koopman matrix\n",
    "U, S, Vh = torch.linalg.svd(K_matrix)\n",
    "\n",
    "# Define significance threshold\n",
    "significant_threshold = 1e-5\n",
    "significant_indices = torch.where(S > significant_threshold)[0]\n",
    "print(f\"Number of significant singular values: {len(significant_indices)} out of {len(S)}\")\n",
    "\n",
    "# Extract significant singular vectors\n",
    "significant_U = U[:, significant_indices]\n",
    "significant_S = S[significant_indices]\n",
    "\n",
    "# Encode all samples\n",
    "with torch.no_grad():\n",
    "    all_encodings = autoencoder._encode(target_ae_inputs)\n",
    "\n",
    "    # Project onto significant left singular vectors\n",
    "    projections = torch.matmul(all_encodings, significant_U)\n",
    "\n",
    "    # Two metrics of importance:\n",
    "    # 1. Raw projection variance\n",
    "    raw_variance = torch.var(projections, dim=0)\n",
    "\n",
    "    # 2. Scaled variance (accounts for singular value effect)\n",
    "    # Scale projections by their singular values\n",
    "    scaled_projections = projections * significant_S\n",
    "    scaled_variance = torch.var(scaled_projections, dim=0)\n",
    "\n",
    "    # Sort by scaled variance (more relevant to the output)\n",
    "    sorted_indices = torch.argsort(scaled_variance, descending=True)\n",
    "\n",
    "    print(\"\\nSignificant directions sorted by SCALED variance:\")\n",
    "    print(\"Rank | Orig Idx | Scaled Var | Raw Var | Singular Value\")\n",
    "    print(\"-----|---------|------------|---------|---------------\")\n",
    "    for i in range(len(significant_indices)):\n",
    "        idx = sorted_indices[i].item()\n",
    "        original_idx = significant_indices[idx].item()\n",
    "        scaled_var = scaled_variance[idx].item()\n",
    "        raw_var = raw_variance[idx].item()\n",
    "        s_value = significant_S[idx].item()\n",
    "        print(f\"{i+1:4d} | {original_idx:7d} | {scaled_var:.6f} | {raw_var:.6f} | {s_value:.6f}\")\n",
    "\n",
    "# Store the high scaled-variance indices\n",
    "high_scaled_var_indices = [significant_indices[idx].item() for idx in sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numbers of high-variance directions to test\n",
    "max_dirs = min(len(significant_indices), 20)\n",
    "n_directions_to_test = [1, 2, 3, 5, min(10, max_dirs), min(15, max_dirs), min(max_dirs, 20)]\n",
    "n_directions_to_test = sorted(list(set(n_directions_to_test)))  # Remove duplicates\n",
    "\n",
    "results = {}\n",
    "for n_dir in n_directions_to_test:\n",
    "    # Select the top n high SCALED-variance directions\n",
    "    test_directions = high_scaled_var_indices[:n_dir]\n",
    "\n",
    "    # Track accuracy changes\n",
    "    original_correct = 0\n",
    "    modified_correct = 0\n",
    "    changed_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(target_ae_inputs)):\n",
    "            # Original processing\n",
    "            x = target_ae_inputs[i].unsqueeze(0)\n",
    "            z = autoencoder._encode(x)\n",
    "            transformed = autoencoder.koopman_matrix(z)\n",
    "            output = autoencoder._decode(transformed)\n",
    "            original_pred = torch.argmax(model.modules[-2:](output)).item()\n",
    "\n",
    "            # Modified processing - zero out projections on high-variance directions\n",
    "            z_proj = torch.zeros_like(z)\n",
    "            for j, idx in enumerate(significant_indices):\n",
    "                if idx.item() not in test_directions:\n",
    "                    # Keep projections for non-high-variance directions\n",
    "                    z_proj += (z @ U[:, idx]) * U[:, idx]\n",
    "\n",
    "            # Transform modified encoding\n",
    "            transformed_modified = autoencoder.koopman_matrix(z_proj)\n",
    "            output_modified = autoencoder._decode(transformed_modified)\n",
    "            modified_pred = torch.argmax(model.modules[-2:](output_modified)).item()\n",
    "\n",
    "            # Track metrics\n",
    "            if original_pred == target_label:\n",
    "                original_correct += 1\n",
    "            if modified_pred == target_label:\n",
    "                modified_correct += 1\n",
    "            if original_pred != modified_pred:\n",
    "                changed_predictions += 1\n",
    "\n",
    "        # Compute statistics\n",
    "        total = len(target_ae_inputs)\n",
    "        results[n_dir] = {\n",
    "            \"original_accuracy\": original_correct / total,\n",
    "            \"modified_accuracy\": modified_correct / total,\n",
    "            \"prediction_change_rate\": changed_predictions / total,\n",
    "        }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClassification Impact Test Results (using SCALED variance):\")\n",
    "print(\"High-var Dirs | Original Acc | Modified Acc | Change Rate\")\n",
    "print(\"-------------|--------------|--------------|------------\")\n",
    "for n_dir, stats in results.items():\n",
    "    print(\n",
    "        f\"{n_dir:12d} | {stats['original_accuracy']:.4f} | {stats['modified_accuracy']:.4f} | {stats['prediction_change_rate']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by RAW variance (not scaled)\n",
    "raw_sorted_indices = torch.argsort(raw_variance, descending=True)\n",
    "high_raw_var_indices = [significant_indices[idx].item() for idx in raw_sorted_indices]\n",
    "\n",
    "print(\"\\nSignificant directions sorted by RAW variance:\")\n",
    "print(\"Rank | Orig Idx | Raw Var | Singular Value | Scaled Var\")\n",
    "print(\"-----|---------|---------|----------------|------------\")\n",
    "for i in range(len(significant_indices)):\n",
    "    idx = raw_sorted_indices[i].item()\n",
    "    original_idx = significant_indices[idx].item()\n",
    "    raw_var = raw_variance[idx].item()\n",
    "    s_value = significant_S[idx].item()\n",
    "    scaled_var = scaled_variance[idx].item()\n",
    "    print(f\"{i+1:4d} | {original_idx:7d} | {raw_var:.6f} | {s_value:.6f} | {scaled_var:.6f}\")\n",
    "\n",
    "# Test removing high RAW variance directions\n",
    "results_raw = {}\n",
    "for n_dir in n_directions_to_test:\n",
    "    # Select the top n high RAW-variance directions\n",
    "    test_directions = high_raw_var_indices[:n_dir]\n",
    "\n",
    "    # Track accuracy changes\n",
    "    original_correct = 0\n",
    "    modified_correct = 0\n",
    "    changed_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(target_ae_inputs)):\n",
    "            # Original processing\n",
    "            x = target_ae_inputs[i].unsqueeze(0)\n",
    "            z = autoencoder._encode(x)\n",
    "            transformed = autoencoder.koopman_matrix(z)\n",
    "            output = autoencoder._decode(transformed)\n",
    "            original_pred = torch.argmax(model.modules[-2:](output)).item()\n",
    "\n",
    "            # Modified processing - zero out projections on high-variance directions\n",
    "            z_proj = torch.zeros_like(z)\n",
    "            for j, idx in enumerate(significant_indices):\n",
    "                if idx.item() not in test_directions:\n",
    "                    # Keep projections for non-high-variance directions\n",
    "                    z_proj += (z @ U[:, idx]) * U[:, idx]\n",
    "\n",
    "            # Transform modified encoding\n",
    "            transformed_modified = autoencoder.koopman_matrix(z_proj)\n",
    "            output_modified = autoencoder._decode(transformed_modified)\n",
    "            modified_pred = torch.argmax(model.modules[-2:](output_modified)).item()\n",
    "\n",
    "            # Track metrics\n",
    "            if original_pred == target_label:\n",
    "                original_correct += 1\n",
    "            if modified_pred == target_label:\n",
    "                modified_correct += 1\n",
    "            if original_pred != modified_pred:\n",
    "                changed_predictions += 1\n",
    "\n",
    "        # Compute statistics\n",
    "        total = len(target_ae_inputs)\n",
    "        results_raw[n_dir] = {\n",
    "            \"original_accuracy\": original_correct / total,\n",
    "            \"modified_accuracy\": modified_correct / total,\n",
    "            \"prediction_change_rate\": changed_predictions / total,\n",
    "        }\n",
    "\n",
    "print(\"\\nClassification Impact Test Results (using RAW variance):\")\n",
    "print(\"High-var Dirs | Original Acc | Modified Acc | Change Rate\")\n",
    "print(\"-------------|--------------|--------------|------------\")\n",
    "for n_dir, stats in results_raw.items():\n",
    "    print(\n",
    "        f\"{n_dir:12d} | {stats['original_accuracy']:.4f} | {stats['modified_accuracy']:.4f} | {stats['prediction_change_rate']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots with both visualization approaches\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=[\"Approach 1: Singular Value Allocation\", \"Approach 2: Variance Transformation\"],\n",
    ")\n",
    "\n",
    "# Get original indices and convert to numpy\n",
    "orig_indices = significant_indices.cpu().numpy()\n",
    "raw_var = raw_variance.cpu().numpy()\n",
    "sing_vals = significant_S.cpu().numpy()\n",
    "scaled_var = scaled_variance.cpu().numpy()\n",
    "\n",
    "# First approach: Raw Variance vs. Singular Value\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=raw_var,\n",
    "        y=sing_vals,\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=scaled_var,\n",
    "            colorscale=\"Viridis\",\n",
    "            colorbar=dict(title=\"Scaled Variance\", x=0.45),\n",
    "            showscale=True,\n",
    "        ),\n",
    "        text=[str(idx) for idx in orig_indices],\n",
    "        textposition=\"top center\",\n",
    "        hovertemplate=\"Mode: %{text}<br>Raw Variance: %{x:.6f}<br>Singular Value: %{y:.4f}<extra></extra>\",\n",
    "        name=\"Modes\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "# Second approach: Raw Variance vs. Scaled Variance\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=raw_var,\n",
    "        y=scaled_var,\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=sing_vals,\n",
    "            colorscale=\"Plasma\",\n",
    "            colorbar=dict(title=\"Singular Value\", x=1.0),\n",
    "            showscale=True,\n",
    "        ),\n",
    "        text=[str(idx) for idx in orig_indices],\n",
    "        textposition=\"top center\",\n",
    "        hovertemplate=\"Mode: %{text}<br>Raw Variance: %{x:.6f}<br>Scaled Variance: %{y:.4f}<extra></extra>\",\n",
    "        name=\"Modes\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "# Log scales for clearer visualization\n",
    "fig.update_xaxes(type=\"log\", title_text=\"Raw Variance (log scale)\", row=1, col=1)\n",
    "fig.update_yaxes(type=\"log\", title_text=\"Singular Value (log scale)\", row=1, col=1)\n",
    "\n",
    "fig.update_xaxes(type=\"log\", title_text=\"Raw Variance (log scale)\", row=1, col=2)\n",
    "fig.update_yaxes(type=\"log\", title_text=\"Scaled Variance (log scale)\", row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Koopman's Feature Amplification Strategy: Two Complementary Views\",\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need data from multiple classes for this analysis\n",
    "classes_to_analyze = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # MNIST digits\n",
    "class_encodings = {}\n",
    "class_projections = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in classes_to_analyze:\n",
    "        # Get samples for this class\n",
    "        class_idx = torch.where(labels == c)[0]\n",
    "        if len(class_idx) > 0:\n",
    "            # Encode samples\n",
    "            class_inputs = ae_inputs[class_idx]\n",
    "            encodings = autoencoder._encode(class_inputs)\n",
    "            class_encodings[c] = encodings\n",
    "\n",
    "            # Project onto significant singular vectors\n",
    "            proj = torch.matmul(encodings, significant_U)\n",
    "            class_projections[c] = proj\n",
    "\n",
    "    # Compute discriminative power metrics for each direction\n",
    "    # 1. Fisher's discriminant ratio (between-class / within-class variance)\n",
    "    fisher_scores = []\n",
    "\n",
    "    for i in range(len(significant_indices)):\n",
    "        # Get projections for all classes onto this direction\n",
    "        class_means = []\n",
    "        class_vars = []\n",
    "        all_projs = []\n",
    "\n",
    "        for c, projs in class_projections.items():\n",
    "            dir_projs = projs[:, i]\n",
    "            class_means.append(torch.mean(dir_projs).item())\n",
    "            class_vars.append(torch.var(dir_projs).item())\n",
    "            all_projs.append(dir_projs)\n",
    "\n",
    "        # Between-class variance\n",
    "        between_var = np.var(class_means) * len(class_means)\n",
    "\n",
    "        # Within-class variance (weighted average)\n",
    "        total_samples = sum(len(p) for p in all_projs)\n",
    "        within_var = sum(\n",
    "            v * len(class_projections[c]) / total_samples\n",
    "            for c, v in zip(class_projections.keys(), class_vars)\n",
    "        )\n",
    "\n",
    "        # Fisher score (higher = more discriminative)\n",
    "        fisher_score = between_var / (within_var + 1e-10)\n",
    "        fisher_scores.append(fisher_score)\n",
    "\n",
    "    # Associate with original indices and other metrics\n",
    "    mode_metrics = []\n",
    "    for i, idx in enumerate(significant_indices):\n",
    "        mode_metrics.append(\n",
    "            {\n",
    "                \"mode\": idx.item(),\n",
    "                \"singular_value\": significant_S[i].item(),\n",
    "                \"raw_variance\": raw_variance[i].item(),\n",
    "                \"scaled_variance\": scaled_variance[i].item(),\n",
    "                \"fisher_score\": fisher_scores[i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Sort by Fisher score (discriminative power)\n",
    "    discriminative_modes = sorted(mode_metrics, key=lambda x: x[\"fisher_score\"], reverse=True)\n",
    "\n",
    "# Print results sorted by discriminative power\n",
    "print(\"\\nModes ranked by discriminative power (Fisher score):\")\n",
    "print(\"Rank | Mode | Fisher Score | Singular Value | Raw Variance\")\n",
    "print(\"-----|------|-------------|----------------|------------\")\n",
    "for i, mode in enumerate(discriminative_modes[:20]):\n",
    "    print(\n",
    "        f\"{i+1:4d} | {mode['mode']:4d} | {mode['fisher_score']:11.4f} | {mode['singular_value']:14.4f} | {mode['raw_variance']:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import HBox, VBox, interact, widgets\n",
    "\n",
    "# Get the modes with non-zero singular values\n",
    "valid_modes = [\n",
    "    idx.item() for idx, sv in zip(significant_indices, significant_S) if sv > significant_threshold\n",
    "]\n",
    "mode_options = [\n",
    "    (\n",
    "        f\"Mode {m} (σ={S[m]:.2f}, Fisher={next((x['fisher_score'] for x in discriminative_modes if x['mode'] == m), 0):.2f})\",\n",
    "        m,\n",
    "    )\n",
    "    for m in valid_modes\n",
    "]\n",
    "\n",
    "\n",
    "# Function to create visualizations\n",
    "def create_mode_visualization(n_dimensions, mode1=None, mode2=None, mode3=None):\n",
    "    # Select modes based on inputs\n",
    "    selected_modes = [m for m in [mode1, mode2, mode3] if m is not None]\n",
    "    if len(selected_modes) < n_dimensions:\n",
    "        return go.Figure().update_layout(title=\"Please select modes for all dimensions\")\n",
    "\n",
    "    # Create the appropriate visualization based on dimensions\n",
    "    if n_dimensions == 1:\n",
    "        return create_1d_visualization(selected_modes[0])\n",
    "    elif n_dimensions == 2:\n",
    "        return create_2d_visualization(selected_modes[0], selected_modes[1])\n",
    "    else:  # 3D\n",
    "        return create_3d_visualization(selected_modes[0], selected_modes[1], selected_modes[2])\n",
    "\n",
    "\n",
    "def create_1d_visualization(mode):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Find index in significant_indices\n",
    "    mode_idx = torch.where(significant_indices == mode)[0].item()\n",
    "\n",
    "    # Add box plots for each class\n",
    "    for c in sorted(class_projections.keys()):\n",
    "        values = class_projections[c][:, mode_idx].cpu().numpy()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=values,\n",
    "                name=f\"Class {c}\",\n",
    "                boxpoints=\"all\",  # Show all points\n",
    "                jitter=0.3,\n",
    "                pointpos=-1.8,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Get the Fisher score and singular value\n",
    "    fisher = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode), 0)\n",
    "    singular_value = S[mode].item()\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Class Distribution on Mode {mode}\",\n",
    "        yaxis_title=f\"Projection Value (σ={singular_value:.4f}, Fisher={fisher:.4f})\",\n",
    "        height=600,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_2d_visualization(mode1, mode2):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Find indices in significant_indices\n",
    "    idx1 = torch.where(significant_indices == mode1)[0].item()\n",
    "    idx2 = torch.where(significant_indices == mode2)[0].item()\n",
    "\n",
    "    # Get Fisher scores and singular values\n",
    "    fisher1 = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode1), 0)\n",
    "    fisher2 = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode2), 0)\n",
    "    sv1 = S[mode1].item()\n",
    "    sv2 = S[mode2].item()\n",
    "\n",
    "    # Add scatter plots for each class\n",
    "    for c in sorted(class_projections.keys()):\n",
    "        x = class_projections[c][:, idx1].cpu().numpy()\n",
    "        y = class_projections[c][:, idx2].cpu().numpy()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"markers\", name=f\"Class {c}\", marker=dict(size=8)))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Class Separation by Selected Modes\",\n",
    "        xaxis_title=f\"Mode {mode1} (σ={sv1:.4f}, Fisher={fisher1:.4f})\",\n",
    "        yaxis_title=f\"Mode {mode2} (σ={sv2:.4f}, Fisher={fisher2:.4f})\",\n",
    "        height=600,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_3d_visualization(mode1, mode2, mode3):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Find indices in significant_indices\n",
    "    idx1 = torch.where(significant_indices == mode1)[0].item()\n",
    "    idx2 = torch.where(significant_indices == mode2)[0].item()\n",
    "    idx3 = torch.where(significant_indices == mode3)[0].item()\n",
    "\n",
    "    # Get Fisher scores and singular values\n",
    "    fisher1 = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode1), 0)\n",
    "    fisher2 = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode2), 0)\n",
    "    fisher3 = next((x[\"fisher_score\"] for x in discriminative_modes if x[\"mode\"] == mode3), 0)\n",
    "    sv1 = S[mode1].item()\n",
    "    sv2 = S[mode2].item()\n",
    "    sv3 = S[mode3].item()\n",
    "\n",
    "    # Add 3D scatter for each class\n",
    "    for c in sorted(class_projections.keys()):\n",
    "        x = class_projections[c][:, idx1].cpu().numpy()\n",
    "        y = class_projections[c][:, idx2].cpu().numpy()\n",
    "        z = class_projections[c][:, idx3].cpu().numpy()\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=x, y=y, z=z, mode=\"markers\", name=f\"Class {c}\", marker=dict(size=4, opacity=0.8)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"3D Class Separation by Selected Modes\",\n",
    "        scene=dict(\n",
    "            xaxis_title=f\"Mode {mode1} (σ={sv1:.4f}, Fisher={fisher1:.4f})\",\n",
    "            yaxis_title=f\"Mode {mode2} (σ={sv2:.4f}, Fisher={fisher2:.4f})\",\n",
    "            zaxis_title=f\"Mode {mode3} (σ={sv3:.4f}, Fisher={fisher3:.4f})\",\n",
    "        ),\n",
    "        height=700,\n",
    "        width=900,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create interactive widget\n",
    "@interact(\n",
    "    n_dimensions=widgets.RadioButtons(\n",
    "        options=[(f\"{i}D\", i) for i in range(1, 4)],\n",
    "        value=3,\n",
    "        description=\"Dimensions:\",\n",
    "        style={\"description_width\": \"initial\"},\n",
    "    ),\n",
    "    mode1=widgets.Dropdown(\n",
    "        options=mode_options,\n",
    "        value=mode_options[0][1] if mode_options else None,\n",
    "        description=\"X-axis Mode:\",\n",
    "        style={\"description_width\": \"initial\"},\n",
    "        disabled=False,\n",
    "    ),\n",
    "    mode2=widgets.Dropdown(\n",
    "        options=mode_options,\n",
    "        value=mode_options[1][1] if len(mode_options) > 1 else None,\n",
    "        description=\"Y-axis Mode:\",\n",
    "        style={\"description_width\": \"initial\"},\n",
    "        disabled=False,\n",
    "    ),\n",
    "    mode3=widgets.Dropdown(\n",
    "        options=mode_options,\n",
    "        value=mode_options[2][1] if len(mode_options) > 2 else None,\n",
    "        description=\"Z-axis Mode:\",\n",
    "        style={\"description_width\": \"initial\"},\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "def update_visualization(n_dimensions, mode1, mode2, mode3):\n",
    "    fig = create_mode_visualization(n_dimensions, mode1, mode2, mode3)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Encode examples\n",
    "    correct_encodings = autoencoder._encode(correct_ae_inputs)  # Shape: [n_correct, d]\n",
    "    misclassified_encodings = autoencoder._encode(misclassified_ae_inputs)  # Shape: [n_misclass, d]\n",
    "\n",
    "    # Obtain SVD of Koopman matrix\n",
    "    U, S, Vh = torch.linalg.svd(K_matrix)\n",
    "\n",
    "    # Identify significant modes\n",
    "    significant_threshold = 1e-5\n",
    "    significant_modes = torch.where(S > significant_threshold)[0]\n",
    "    sig_U = U[:, significant_modes]\n",
    "    sig_S = S[significant_modes]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Project encodings onto left singular vectors\n",
    "        correct_U_proj = torch.matmul(correct_encodings, sig_U)\n",
    "        misclass_U_proj = torch.matmul(misclassified_encodings, sig_U)\n",
    "\n",
    "        # Compute standard statistics\n",
    "        correct_mean = torch.mean(correct_U_proj, dim=0)\n",
    "        correct_std = torch.std(correct_U_proj, dim=0)\n",
    "        misclass_mean = torch.mean(misclass_U_proj, dim=0)\n",
    "        misclass_std = torch.std(misclass_U_proj, dim=0)\n",
    "\n",
    "        # Compute standardized effect size (Cohen's d)\n",
    "        n_correct = correct_U_proj.shape[0]\n",
    "        n_misclass = misclass_U_proj.shape[0]\n",
    "        pooled_std = torch.sqrt(\n",
    "            ((n_correct - 1) * correct_std**2 + (n_misclass - 1) * misclass_std**2)\n",
    "            / (n_correct + n_misclass - 2)\n",
    "        )\n",
    "        effect_size = (misclass_mean - correct_mean) / pooled_std\n",
    "\n",
    "        # Calculate percent difference in magnitude\n",
    "        pct_diff = 100 * (misclass_mean - correct_mean) / torch.abs(correct_mean)\n",
    "\n",
    "        # Rank modes by absolute effect size\n",
    "        ranked_indices = torch.argsort(torch.abs(effect_size), descending=True)\n",
    "\n",
    "print(\"Modal Projection Analysis Results:\")\n",
    "print(\"Mode | Singular Value | Effect Size | % Difference\")\n",
    "print(\"-----|---------------|------------|-------------\")\n",
    "\n",
    "for i in range(len(significant_modes)):\n",
    "    mode_idx = ranked_indices[i]\n",
    "    mode = significant_modes[mode_idx]\n",
    "    s_val = sig_S[mode_idx].item()\n",
    "    d_val = effect_size[mode_idx].item()\n",
    "    p_diff = pct_diff[mode_idx].item()\n",
    "\n",
    "    print(f\"{mode:4d} | {s_val:13.4f} | {d_val:10.4f} | {p_diff:+11.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # SVD decomposition of Koopman matrix\n",
    "    U, S, Vh = torch.linalg.svd(K_matrix)\n",
    "\n",
    "    # Identify significant modes\n",
    "    significant_threshold = 1e-5\n",
    "    significant_modes = torch.where(S > significant_threshold)[0]\n",
    "\n",
    "    # Compute modal statistics for correctly classified examples\n",
    "    correct_encodings = autoencoder._encode(correct_ae_inputs)\n",
    "    correct_projections = torch.matmul(correct_encodings, U)\n",
    "    correct_mean_proj = torch.mean(correct_projections, dim=0)\n",
    "\n",
    "    # Select modes with highest discriminative power (based on previous analysis)\n",
    "    target_modes = ranked_indices  # Top modes from effect size analysis\n",
    "\n",
    "    # Process a misclassified example\n",
    "    example_idx = 0  # Select first misclassified example\n",
    "    x_mis = misclassified_ae_inputs[example_idx].unsqueeze(0)\n",
    "\n",
    "    # Original classification\n",
    "    mlp_pred = torch.argmax(model(misclassifed_mlp_inputs[example_idx].unsqueeze(0)))\n",
    "\n",
    "    # Original Koopman transformation and prediction\n",
    "    z_mis = autoencoder._encode(x_mis)\n",
    "    koopman_transformed = autoencoder.koopman_matrix(z_mis)\n",
    "    koopman_output = autoencoder._decode(koopman_transformed)\n",
    "\n",
    "    # Push through penultimate layer\n",
    "    koopman_pred = torch.argmax(model.modules[-2:](koopman_output)).item()\n",
    "\n",
    "    print(\n",
    "        f\"MLP prediction: {mlp_pred}, Koopman prediction: {koopman_pred}, True class: {target_label}\"\n",
    "    )\n",
    "\n",
    "    # Modal surgery: replace projections for specific modes\n",
    "    for n_modes in list(range(20)):\n",
    "        # Project into modal space\n",
    "        z_proj = torch.matmul(z_mis, U)\n",
    "\n",
    "        # Replace projections for selected modes\n",
    "        for i in range(n_modes):\n",
    "            mode = target_modes[i]\n",
    "            z_proj[0, mode] = correct_mean_proj[mode]\n",
    "\n",
    "        # Undo projection\n",
    "        test = autoencoder._decode(torch.matmul(z_proj, U.t()))\n",
    "\n",
    "        # Transform through remaining steps: z_proj → z_proj Σ → z_proj Σ V^T\n",
    "        # Note: We construct a diagonal matrix from S for matrix multiplication\n",
    "        S_diag = torch.diag(S)\n",
    "        transformed = torch.matmul(z_proj, S_diag)\n",
    "        transformed = torch.matmul(transformed, Vh)\n",
    "\n",
    "        # Decode and classify\n",
    "        corrected_output = autoencoder._decode(transformed)\n",
    "        corrected_pred = torch.argmax(model.modules[-2:](corrected_output)).item()\n",
    "\n",
    "        status = \"FIXED ✓\" if corrected_pred == target_label else \"still wrong ✗\"\n",
    "        print(f\"After correcting top {n_modes} modes: {status} (koopman pred={corrected_pred})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
