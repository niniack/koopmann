{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import plotly.colors as pc\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from plotly.subplots import make_subplots\n",
    "from rich import print as rprint\n",
    "from scipy.spatial import procrustes\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "from analysis.common import load_autoencoder, load_model\n",
    "from analysis.residual_alignment_methods import alignment, plotsvals, sab, trajectories\n",
    "from koopmann import aesthetics\n",
    "\n",
    "# from koopmann import aesthetics\n",
    "from koopmann.data import (\n",
    "    DatasetConfig,\n",
    "    get_dataset_class,\n",
    ")\n",
    "from koopmann.models import MLP, Autoencoder, ExponentialKoopmanAutencoder, ResMLP\n",
    "from koopmann.models.layers import LinearLayer\n",
    "from koopmann.utils import (\n",
    "    get_device,\n",
    ")\n",
    "from koopmann.visualization import plot_decision_boundary\n",
    "from scripts.train_ae.losses import pad_act\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/scratch/nsa325/koopmann_model_saves\"\n",
    "dim = 2048\n",
    "k = 1\n",
    "scale_idx = 0\n",
    "\n",
    "rank = 20\n",
    "flavor = f\"lowrank_{rank}\"\n",
    "# flavor = \"standard\"\n",
    "# flavor = \"exponential\"\n",
    "\n",
    "model_name = \"resmlp\"\n",
    "ae_name = f\"dim_{dim}_k_{k}_loc_{scale_idx}_{flavor}_autoencoder_mnist_model\"\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchnorm': True, 'bias': False, 'created_at': '2025-03-26T01:46:32.117345', 'dataset': 'MNISTDataset', 'hidden_config': [784, 784, 784, 784], 'in_features': 784, 'model_class': 'ResMLP', 'nonlinearity': 'relu', 'out_features': 10, 'stochastic_depth_mode': 'batch', 'stochastic_depth_prob': 0.0}\n"
     ]
    }
   ],
   "source": [
    "model, model_metadata = load_model(file_dir, model_name)\n",
    "model.hook_model()\n",
    "print(model_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "dataset_config = DatasetConfig(\n",
    "    dataset_name=model_metadata[\"dataset\"],\n",
    "    num_samples=3_000,\n",
    "    split=\"test\",\n",
    "    seed=42,\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=dataset_config.dataset_name)\n",
    "dataset = DatasetClass(config=dataset_config)\n",
    "dataloader = DataLoader(dataset, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_class = 1\n",
    "# idx = torch.where(train_dataset.labels == target_class)[0]\n",
    "# subset = Subset(train_dataset, idx)\n",
    "# loader = torch.utils.data.DataLoader(train_dataset, batch_size=1_000, shuffle=True)\n",
    "# data, labels = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute initial PCA\n",
    "# def compute_reference_bases(data):\n",
    "#     # Compute PCA reference basis\n",
    "#     pca = PCA(n_components=3)\n",
    "#     ref = pca.fit_transform(data)\n",
    "#     return ref\n",
    "\n",
    "\n",
    "# # Function to align using Procrustes from scipy\n",
    "# def align_using_procrustes(reference_points, new_points):\n",
    "#     _, new_points_aligned, _ = procrustes(reference_points, new_points)\n",
    "#     return new_points_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enable Panel for Jupyter\n",
    "# pn.extension()\n",
    "\n",
    "\n",
    "# def create_3d_scatter_plot(data, labels, axis_range):\n",
    "#     x, y, z = data[:, 0], data[:, 1], data[:, 2]\n",
    "\n",
    "#     str_labels = [str(label) for label in labels]\n",
    "#     color = str_labels\n",
    "\n",
    "#     # pca_scalar_field = np.linalg.norm(ref_a, axis=1)\n",
    "#     # color = pca_scalar_field\n",
    "#     # color_continuous_scale=\"Viridis\")\n",
    "#     fig = px.scatter_3d(x=x, y=y, z=z, color=color)\n",
    "\n",
    "#     fig.update_traces(marker=dict(size=1))\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis=dict(range=axis_range),\n",
    "#             yaxis=dict(range=axis_range),\n",
    "#             zaxis=dict(range=axis_range),\n",
    "#             aspectmode=\"cube\",\n",
    "#             aspectratio=dict(x=1, y=1, z=1),\n",
    "#         ),\n",
    "#         showlegend=False,\n",
    "#     )\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# def process_pca_and_align(data, reference):\n",
    "#     \"\"\"Applies PCA, aligns using Procrustes, and returns aligned data.\"\"\"\n",
    "#     pca = PCA(n_components=3)\n",
    "#     pca_result = pca.fit_transform(data)\n",
    "#     aligned_result = align_using_procrustes(reference, pca_result)\n",
    "#     return aligned_result\n",
    "\n",
    "\n",
    "# def update_plots(data_a, data_b, ref_a, ref_b, labels):\n",
    "#     \"\"\"Updates PCA and RP plots with the given data and references.\"\"\"\n",
    "#     pca_axis_range = [-0.05, 0.05]  # Default axis range\n",
    "\n",
    "#     # First plot: PCA\n",
    "#     aligned_pca_result = process_pca_and_align(data_a, ref_a)\n",
    "#     first_fig = create_3d_scatter_plot(aligned_pca_result, labels, pca_axis_range)\n",
    "\n",
    "#     # Second plot: PCA\n",
    "#     aligned_pca_result = process_pca_and_align(data_b, ref_b)\n",
    "#     second_fig = create_3d_scatter_plot(aligned_pca_result, labels, pca_axis_range)\n",
    "\n",
    "#     return first_fig, second_fig\n",
    "\n",
    "\n",
    "# # Clone and hook model\n",
    "# cloned_model = deepcopy(model)\n",
    "# cloned_model.hook_model()\n",
    "\n",
    "# # Activations from original model\n",
    "# with torch.no_grad():\n",
    "#     _ = cloned_model.forward(data)\n",
    "# act_dict = cloned_model.get_fwd_activations(detach=True)\n",
    "\n",
    "# temp_act_dict = OrderedDict()\n",
    "# temp_act_dict[0] = data.flatten(start_dim=1)\n",
    "# for i in act_dict.keys():\n",
    "#     temp_act_dict[i + 1] = act_dict[i]\n",
    "# act_dict = temp_act_dict\n",
    "\n",
    "# # Get Koopman predictions\n",
    "# k = int(ae_metadata[\"num_scaled\"])\n",
    "# new_keys = list(range(0, k + 1))\n",
    "# decoded_act = (\n",
    "#     autoencoder(x=act_dict[scale_idx], k=k, intermediate=True).predictions.detach().numpy()\n",
    "# )\n",
    "# decoded_act_dict = OrderedDict(zip(new_keys, decoded_act))\n",
    "# ref_decoded = compute_reference_bases(decoded_act_dict[0])\n",
    "\n",
    "# # Get observable predictions\n",
    "# embedded_act = [autoencoder.encoder(act_dict[scale_idx])] * (k + 1)\n",
    "# embedded_act = [\n",
    "#     act if i == 0 else reduce(lambda x, _: autoencoder.koopman_matrix(x), range(i), act)\n",
    "#     for i, act in enumerate(embedded_act)\n",
    "# ]\n",
    "# embedded_act = [act.detach().numpy() for act in embedded_act]\n",
    "# embedded_act_dict = OrderedDict(zip(new_keys, embedded_act))\n",
    "# ref_embedded = compute_reference_bases(embedded_act[0])\n",
    "\n",
    "# # Create slider\n",
    "# layer_select = pn.widgets.IntSlider(name=\"Layer Selector\", start=0, end=k, step=1, value=0)\n",
    "\n",
    "\n",
    "# @pn.depends(layer_select.param.value)\n",
    "# def view(layer_index):\n",
    "#     figs = update_plots(\n",
    "#         decoded_act_dict[layer_index],\n",
    "#         embedded_act_dict[layer_index],\n",
    "#         ref_decoded,\n",
    "#         ref_embedded,\n",
    "#         labels,\n",
    "#     )\n",
    "#     panes = [pn.pane.Plotly(fig) for fig in figs]\n",
    "\n",
    "#     return pn.Row(*panes, align=\"center\")\n",
    "\n",
    "\n",
    "# # Layout\n",
    "# layout = pn.Column(\n",
    "#     pn.Row(layer_select, align=\"center\"),\n",
    "#     view,\n",
    "#     align=\"center\",\n",
    "#     sizing_mode=\"stretch_width\",\n",
    "# )\n",
    "\n",
    "# layout.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
