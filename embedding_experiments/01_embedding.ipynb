{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from analysis.common import load_autoencoder, load_model\n",
    "from koopmann.data import DatasetConfig, get_dataset_class\n",
    "from koopmann.utils import get_device\n",
    "from scripts.train_ae.shape_metrics import Processor, build_acts_dict, prepare_acts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import cuml\n",
    "from cuml.manifold.umap import UMAP as umap\n",
    "from cuml.random_projection import SparseRandomProjection as random_projection\n",
    "from cuml.decomposition import IncrementalPCA as pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/scratch/nsa325/koopmann_model_saves\"\n",
    "dim = 800\n",
    "k_steps = 1\n",
    "scale_idx = 1\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "# rank = 100\n",
    "# flavor = f\"lowrank_{rank}\"\n",
    "flavor = \"standard\"\n",
    "# flavor = \"exponential\"\n",
    "\n",
    "model_name = f\"convresnet_{dataset_name}\"\n",
    "ae_name = f\"dim_{dim}_k_{k_steps}_loc_{scale_idx}_{flavor}_autoencoder_{dataset_name}_model\"\n",
    "# device = get_device()\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_metadata = load_model(file_dir, model_name)\n",
    "model.eval().hook_model().to(device)\n",
    "print(model_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, ae_metadata = load_autoencoder(file_dir, ae_name)\n",
    "autoencoder.eval()\n",
    "print(ae_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset config\n",
    "dataset_config = DatasetConfig(\n",
    "    dataset_name=model_metadata[\"dataset\"],\n",
    "    num_samples=3_000,\n",
    "    split=\"train\",\n",
    "    seed=42,\n",
    ")\n",
    "DatasetClass = get_dataset_class(name=dataset_config.dataset_name)\n",
    "dataset = DatasetClass(config=dataset_config)\n",
    "\n",
    "subset_size = 20_000\n",
    "if subset_size:\n",
    "    subset_indices = list(range(0, subset_size))\n",
    "    dataset = Subset(dataset, subset_indices)\n",
    "\n",
    "batch_size = 3_000\n",
    "batch_size = min(subset_size, batch_size) if subset_size else batch_size\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_dict = {}\n",
    "with safe_open(\n",
    "    f\"{file_dir}/{ae_name}_preprocessing.safetensors\", framework=\"pt\", device=\"cpu\"\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        preproc_dict[k] = f.get_tensor(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_act_dict = build_acts_dict(\n",
    "    data_train_loader=dataloader, model=model, only_first_last=True, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dim_reduce_umap(x, dim):\n",
    "    n_samples = x.shape[0]\n",
    "    # g_embedding = pca(n_components=dim, batch_size=200).fit_transform(x)\n",
    "    # g_embedding = random_projection(n_components=dim).fit_transform(x)\n",
    "    g_embedding = umap(n_neighbors=100, n_components=dim, spread=5, min_dist=0.01).fit_transform(x)\n",
    "    # print(cuml.random_projection.johnson_lindenstrauss_min_dim(n_samples, eps=0.3))\n",
    "    return g_embedding, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "for key, curr_act in orig_act_dict.items():\n",
    "    print(key)\n",
    "    new_dim = 3\n",
    "    processed_act = torch.flatten(curr_act.clone().to(device), start_dim=1)\n",
    "    means = torch.mean(processed_act, dim=0, keepdim=True)\n",
    "    # processed_act -= means.to(device)\n",
    "    processed_act, directions = _dim_reduce_umap(processed_act.numpy(), new_dim)\n",
    "    processed_act = torch.tensor(processed_act)\n",
    "    norms = torch.linalg.norm(processed_act, ord=\"fro\") / 1000\n",
    "    processed_act /= norms.to(device)\n",
    "    # processed_act = Processor._whiten(processed_act, alpha=0.9)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = processed_act.cpu()[:, 0]\n",
    "y = processed_act.cpu()[:, 1]\n",
    "z = processed_act.cpu()[:, 2]\n",
    "\n",
    "\n",
    "# Convert targets to strings to force categorical interpretation\n",
    "target_categories = [str(t) for t in dataset.dataset.targets[:subset_size]]\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    color=target_categories,\n",
    "    color_discrete_sequence=px.colors.qualitative.T10,\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_size=2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopmann-J7sjGzNf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
