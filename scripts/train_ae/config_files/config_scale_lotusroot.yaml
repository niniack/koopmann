train_data: 
  dataset_name: "LotusRootDataset"
  num_samples: 5_000
  split: "train"
  torch_transform: null
  seed: 42
  negative_label: False

optim:
  num_epochs: 500
  learning_rate: 1e-2
  weight_decay: 5e-4
  type: "adamw"

scale:
  model_to_scale: "/scratch/nsa325/koopmann_model_saves/resmlp_lotusroot.safetensors"
  scale_location: 1
  num_scaled_layers: 100

wandb: 
    use_wandb: True
    entity: "nishantaswani"
    project: "koopman_interp"

autoencoder:
  preprocess: True
  pca_dim: 10
  ae_dim: 20
  hidden_config: [30]
  ae_nonlinearity: "leaky_relu"
  batchnorm: False
  lambda_reconstruction: 1e-1
  lambda_state_pred: 1e-1
  lambda_latent_pred: 1e0
  lambda_isometric: 1e-3
  koopman_param: "exponential"
  # koopman_rank: 20

adv: 
    use_adversarial_training: False
    epsilon: 0.08

task_type: "autoencoder"
batch_size: 256
seed: 21
save_name: "lotusroot_model"
save_dir: "/scratch/nsa325/koopmann_model_saves/"
print_freq: 10