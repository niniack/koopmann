program: train.py
name: koopman_interp_sweep
method: grid
metric:
  goal: minimize
  name: train/combined_loss
entity: nishantaswani
project: koopman_interp
num_sweeps: 500
parameters:
  batch_size:
    value: 256
  optim:
    parameters:
      learning_rate:
        values: [1e-1, 5e-2, 1e-2]
      weight_decay:
        values: [1e-2, 1e-3, 5e-4]
      # Not sweepable below
      num_epochs:
        value: 500
      type:
        value: adamw
  autoencoder:
    parameters:
      pca_dim:
        value: 10
      ae_dim:
        values: [30, 50, 80]
      hidden_config:
        values: [[20], [15,30]]
      ae_nonlinearity:
        values: [leaky_relu, gelu, relu, tanh]
      preprocess:
        values: [true, false]
      # Not sweepable below
      lambda_reconstruction:
        value: 1e0
      lambda_state_pred:
        values: [1e0, 1e-1]
      lambda_latent_pred:
        values: [1e0, 1e-1]
      lambda_isometric:
        values: [1e-3, 1e-2]
      batchnorm:
        value: false
      koopman_param: 
        value: "exponential"

  ### Dead zone
  ### Not sweepable
  task_type:
    value: autoencoder
  save_name:
    value: lotusroot_model
  save_dir:
    value: /scratch/nsa325/koopmann_model_saves/
  print_freq:
    value: 10
  seed:
    value: 21
  train_data:
    parameters:
      dataset_name:
        value: LotusRootDataset
      num_samples:
        value: 5000
      split:
        value: train
      torch_transform:
        value: null
      seed:
        value: 42
      negative_label:
        value: false
  scale:
    parameters:
      model_to_scale:
        value: /scratch/nsa325/koopmann_model_saves/resmlp_lotusroot.safetensors
      scale_location:
        value: 1
      num_scaled_layers:
        value: 100
  adv:
    parameters:
      use_adversarial_training:
        value: false
      epsilon:
        value: 0.08
  wandb:
    parameters:
      use_wandb:
        value: true
